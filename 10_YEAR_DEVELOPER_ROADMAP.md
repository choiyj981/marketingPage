# 🚀 3년차 → 10년차 개발자 성장 로드맵

> **학습 철학**: AI 도움을 받아 많은 기능을 구현하고, DevOps에 집중하며, 역공학을 통해 이해하기

---

## 📋 목차

1. [학습 접근법](#학습-접근법)
2. [현재 상태 분석](#현재-상태-분석)
3. [단계별 학습 계획](#단계별-학습-계획)
4. [각 단계별 상세 가이드](#각-단계별-상세-가이드)
5. [학습 체크리스트](#학습-체크리스트)

---

## 🎯 학습 접근법

### 핵심 원칙

1. **구현 우선, 이해는 나중에**
   - AI(Cursor) 도움을 받아 기능을 먼저 구현
   - 작동하는 코드를 보고 역공학으로 이해
   - "왜 이렇게 작동하는가?"를 나중에 질문

2. **DevOps 중심 학습**
   - 모든 기능을 배포 가능한 형태로 구현
   - CI/CD 파이프라인을 통해 자동화
   - 인프라를 코드로 관리(IaC)

3. **실전 프로젝트 기반**
   - 현재 마케팅 페이지 프로젝트를 확장
   - 각 단계마다 실제 사용 가능한 기능 추가
   - 포트폴리오로 활용 가능

---

## 📊 현재 상태 분석

### 현재 기술 스택

| 카테고리 | 기술 | 수준 |
|---------|------|------|
| 프론트엔드 | React + TypeScript + Tailwind CSS | ⭐⭐⭐ |
| 백엔드 | Express.js + TypeScript | ⭐⭐⭐ |
| 데이터베이스 | PostgreSQL | ⭐⭐ |
| 컨테이너 | Docker + Docker Compose | ⭐⭐ |
| CI/CD | GitHub Actions | ⭐⭐ |
| 클라우드 | GCP (기본) | ⭐ |

### 현재 프로젝트 구조

```
마케팅 페이지 프로젝트
├── 프론트엔드 (React)
├── 백엔드 (Express)
├── 데이터베이스 (PostgreSQL)
├── Docker 컨테이너화
└── GitHub Actions 자동 배포
```

---

## 🗺️ 단계별 학습 계획

### 전체 로드맵 개요

```
[현재] → [1단계] → [2단계] → [3단계] → [4단계] → [5단계] → [목표]
  │         │         │         │         │         │
기본      실시간    캐싱    마이크로서비스  쿠버네티스  고급
구조      기능      최적화   아키텍처      오케스트레이션  운영
```

---

## 📚 각 단계별 상세 가이드

---

## 1단계: 실시간 기능 & 고급 인증 (2-3개월)

### 🎯 목표
- 실시간 통신 구현
- 세션 관리 고도화
- 파일 업로드 개선

### 📦 구현할 기능들

#### 1.1 WebSocket 실시간 채팅/알림

**왜 필요한가?**
- 사용자가 페이지를 새로고침하지 않아도 실시간으로 업데이트 받음
- 관리자와 사용자 간 실시간 소통 가능
- 예: 문의사항 답변 시 즉시 알림

**기능 설명:**
```
사용자 A가 문의 작성 → 서버가 WebSocket으로 관리자에게 알림
관리자가 답변 작성 → 서버가 WebSocket으로 사용자 A에게 알림
(페이지 새로고침 없이 실시간 업데이트)
```

**구현 방법:**
1. `ws` 라이브러리로 WebSocket 서버 구축
2. 클라이언트에서 WebSocket 연결
3. 실시간 메시지 송수신

**학습 포인트:**
- WebSocket vs HTTP 차이점
- 연결 유지 메커니즘
- 재연결 로직

#### 1.2 Redis 세션 관리

**왜 필요한가?**
- 현재 PostgreSQL에 세션 저장 → 느림
- 여러 서버로 확장 시 세션 공유 불가
- Redis는 메모리 기반이라 매우 빠름

**기능 설명:**
```
사용자 로그인 → 세션을 Redis에 저장 (메모리, 매우 빠름)
다른 서버에서도 같은 Redis 접근 → 세션 공유 가능
세션 만료 시 자동 삭제
```

**구현 방법:**
1. Redis Docker 컨테이너 추가
2. `connect-redis`로 Express 세션 저장소 변경
3. 세션 TTL(Time To Live) 설정

**학습 포인트:**
- 메모리 vs 디스크 저장 차이
- 세션 스토어의 역할
- 분산 시스템에서의 세션 공유

#### 1.3 파일 업로드 개선 (멀티파트, 이미지 최적화)

**왜 필요한가?**
- 대용량 파일 업로드 지원
- 이미지 자동 리사이징
- CDN 연동 준비

**기능 설명:**
```
사용자가 이미지 업로드
→ 서버에서 자동으로 썸네일 생성
→ 원본과 썸네일을 S3/Cloud Storage에 저장
→ CDN URL 반환 (빠른 로딩)
```

**구현 방법:**
1. `sharp` 라이브러리로 이미지 리사이징
2. GCP Cloud Storage 연동
3. 업로드 진행률 표시

**학습 포인트:**
- 스트리밍 업로드
- 이미지 처리 파이프라인
- 객체 스토리지 개념

### 🔧 기술 스택 추가

- `ws`: WebSocket 서버
- `redis`: Redis 클라이언트
- `sharp`: 이미지 처리
- `@google-cloud/storage`: GCP 스토리지

### 📝 체크리스트

- [ ] WebSocket 서버 구현
- [ ] 실시간 알림 기능
- [ ] Redis 세션 스토어 연동
- [ ] 이미지 업로드 & 리사이징
- [ ] Cloud Storage 연동
- [ ] Docker Compose에 Redis 추가

---

## 2단계: 성능 최적화 & 캐싱 (2-3개월)

### 🎯 목표
- 응답 속도 개선
- 데이터베이스 쿼리 최적화
- 캐싱 전략 수립

### 📦 구현할 기능들

#### 2.1 Redis 캐싱 레이어

**왜 필요한가?**
- 같은 데이터를 매번 DB에서 조회 → 느림
- Redis에 캐시 저장 → 매우 빠른 응답
- DB 부하 감소

**기능 설명:**
```
첫 번째 요청: DB 조회 → Redis에 저장 (예: 100ms)
두 번째 요청: Redis에서 조회 → 즉시 반환 (예: 1ms)
캐시 만료 시: 다시 DB 조회 → Redis 갱신
```

**구현 방법:**
1. 자주 조회되는 데이터 식별 (블로그 목록, 제품 목록)
2. Redis 캐싱 미들웨어 작성
3. 캐시 무효화 전략 수립

**학습 포인트:**
- 캐시 히트/미스 개념
- 캐시 전략 (Cache-Aside, Write-Through 등)
- 캐시 무효화 타이밍

#### 2.2 데이터베이스 쿼리 최적화

**왜 필요한가?**
- 느린 쿼리 → 사용자 경험 저하
- 인덱스 없으면 전체 테이블 스캔
- N+1 쿼리 문제 해결

**기능 설명:**
```
나쁜 예: 블로그 10개 조회
→ 블로그 목록 쿼리 1번
→ 각 블로그마다 작성자 조회 쿼리 10번
→ 총 11번 쿼리

좋은 예: JOIN 사용
→ 블로그 + 작성자 정보를 한 번에 조회
→ 총 1번 쿼리
```

**구현 방법:**
1. `EXPLAIN ANALYZE`로 쿼리 분석
2. 필요한 인덱스 추가
3. Drizzle ORM의 관계 쿼리 최적화

**학습 포인트:**
- 인덱스의 역할과 종류
- 쿼리 실행 계획 분석
- ORM의 N+1 문제 해결

#### 2.3 CDN (Content Delivery Network) 연동

**왜 필요한가?**
- 정적 파일(이미지, CSS, JS)을 전 세계 서버에 분산
- 사용자와 가까운 서버에서 제공 → 빠른 로딩
- 원본 서버 부하 감소

**기능 설명:**
```
한국 사용자: 한국 CDN 서버에서 이미지 다운로드
미국 사용자: 미국 CDN 서버에서 이미지 다운로드
(각자 가까운 서버 사용 → 빠름)
```

**구현 방법:**
1. Cloudflare 또는 GCP CDN 설정
2. 정적 파일을 CDN URL로 변경
3. 캐시 헤더 설정

**학습 포인트:**
- CDN의 동작 원리
- 엣지 캐싱
- 캐시 무효화 전략

#### 2.4 GraphQL API (선택사항)

**왜 필요한가?**
- REST API는 필요한 데이터만 선택 불가
- GraphQL은 클라이언트가 필요한 필드만 요청
- 네트워크 트래픽 감소

**기능 설명:**
```
REST: /api/blog/1 → 모든 필드 반환 (제목, 내용, 작성자, 댓글 등)
GraphQL: { blog(id: 1) { title, author } } → 제목과 작성자만 반환
```

**구현 방법:**
1. `@apollo/server` 또는 `graphql-yoga` 설정
2. 스키마 정의
3. 리졸버 구현

**학습 포인트:**
- GraphQL vs REST 차이
- N+1 문제와 DataLoader
- 스키마 설계

### 🔧 기술 스택 추가

- `ioredis`: Redis 클라이언트 (고급 기능)
- `@apollo/server`: GraphQL 서버 (선택)
- Cloudflare/GCP CDN

### 📝 체크리스트

- [ ] Redis 캐싱 미들웨어 구현
- [ ] 주요 API 엔드포인트 캐싱
- [ ] 데이터베이스 인덱스 최적화
- [ ] 쿼리 성능 분석 및 개선
- [ ] CDN 연동
- [ ] 성능 모니터링 도구 연동

---

## 3단계: 검색 엔진 & 고급 기능 (2-3개월)

### 🎯 목표
- 전문 검색 기능 구현
- 결제 시스템 연동
- 고급 보안 기능

### 📦 구현할 기능들

#### 3.1 Elasticsearch 검색 엔진

**왜 필요한가?**
- PostgreSQL의 `LIKE` 검색은 느리고 부정확
- Elasticsearch는 전문 검색, 자동완성, 오타 교정 지원
- 대용량 데이터에서도 빠른 검색

**기능 설명:**
```
사용자가 "마케팅" 검색
→ Elasticsearch가 블로그, 제품, 리소스에서 검색
→ 관련도 순으로 정렬
→ 자동완성 제안 ("마케팅 도구", "마케팅 전략" 등)
```

**구현 방법:**
1. Elasticsearch Docker 컨테이너 추가
2. 데이터 인덱싱 (블로그, 제품 등)
3. 검색 API 구현
4. 실시간 인덱싱 (데이터 변경 시)

**학습 포인트:**
- 역인덱스(Inverted Index) 개념
- 분석기(Analyzer) 설정
- 검색 점수(Relevance Score)

#### 3.2 결제 시스템 연동 (I'mport/Toss Payments)

**왜 필요한가?**
- 제품 구매 기능 추가
- 실제 결제 처리
- 결제 보안 및 검증

**기능 설명:**
```
사용자가 제품 구매 클릭
→ 결제 페이지로 이동
→ 결제 정보 입력
→ 결제 API 호출
→ 결제 검증 (서버에서)
→ 주문 완료
```

**구현 방법:**
1. I'mport 또는 Toss Payments SDK 연동
2. 결제 위변조 방지 (서버 검증)
3. 결제 내역 저장
4. 환불 처리

**학습 포인트:**
- PG사(Payment Gateway) 연동
- 결제 보안 (웹훅 검증)
- 결제 상태 관리

#### 3.3 Rate Limiting & 보안 강화

**왜 필요한가?**
- 무차별 공격 방지
- API 남용 방지
- 서버 보호

**기능 설명:**
```
Rate Limiting: 같은 IP에서 1분에 10번만 요청 가능
→ 11번째 요청 시 429 에러 반환
→ Redis에 요청 횟수 카운트 저장
```

**구현 방법:**
1. `express-rate-limit` 미들웨어
2. Redis에 요청 카운트 저장
3. CSRF 토큰 추가
4. XSS 방지 (입력 검증)

**학습 포인트:**
- Rate Limiting 알고리즘
- CSRF 공격 방지
- XSS/SQL Injection 방지

#### 3.4 이메일 발송 시스템

**왜 필요한가?**
- 회원가입 인증
- 비밀번호 재설정
- 알림 메일

**기능 설명:**
```
사용자가 회원가입
→ 인증 이메일 발송
→ 이메일 링크 클릭 시 계정 활성화
→ SendGrid/SES로 이메일 전송
```

**구현 방법:**
1. SendGrid 또는 AWS SES 연동
2. 이메일 템플릿 작성
3. 큐 시스템으로 비동기 발송

**학습 포인트:**
- SMTP vs API 기반 이메일
- 이메일 템플릿 엔진
- 큐 시스템의 역할

### 🔧 기술 스택 추가

- `@elastic/elasticsearch`: Elasticsearch 클라이언트
- `@iamport/iamport-nodejs`: I'mport SDK
- `express-rate-limit`: Rate Limiting
- `nodemailer`: 이메일 발송
- `bull` 또는 `bullmq`: 작업 큐

### 📝 체크리스트

- [ ] Elasticsearch 설정 및 인덱싱
- [ ] 검색 API 구현
- [ ] 자동완성 기능
- [ ] 결제 시스템 연동
- [ ] 결제 검증 로직
- [ ] Rate Limiting 구현
- [ ] CSRF/XSS 방지
- [ ] 이메일 발송 시스템

---

## 4단계: 마이크로서비스 아키텍처 (3-4개월)

### 🎯 목표
- 모놀리식을 마이크로서비스로 분리
- 서비스 간 통신 구현
- 분산 시스템 이해

### 📦 구현할 기능들

#### 4.1 서비스 분리 전략

**왜 필요한가?**
- 현재 모든 기능이 하나의 서버에 있음
- 서비스별로 독립적 배포 불가
- 한 서비스 장애가 전체에 영향

**기능 설명:**
```
현재 (모놀리식):
[Express 서버]
  ├── 사용자 관리
  ├── 블로그 관리
  ├── 제품 관리
  └── 결제 처리

변경 후 (마이크로서비스):
[API Gateway]
  ├── [User Service] - 사용자 관리
  ├── [Content Service] - 블로그/제품
  ├── [Payment Service] - 결제
  └── [Notification Service] - 알림
```

**구현 방법:**
1. 도메인별로 서비스 분리
2. 각 서비스는 독립적인 데이터베이스
3. API Gateway로 라우팅

**학습 포인트:**
- 모놀리식 vs 마이크로서비스
- 서비스 경계 정의
- 데이터 일관성 (분산 트랜잭션)

#### 4.2 API Gateway 구현

**왜 필요한가?**
- 클라이언트는 여러 서비스의 엔드포인트를 알 필요 없음
- 인증/인가를 한 곳에서 처리
- 로드 밸런싱 및 라우팅

**기능 설명:**
```
클라이언트 요청: /api/users/me
→ API Gateway가 요청 받음
→ JWT 토큰 검증
→ User Service로 라우팅
→ 응답 반환
```

**구현 방법:**
1. `express-gateway` 또는 직접 구현
2. JWT 토큰 검증 미들웨어
3. 서비스 디스커버리 연동

**학습 포인트:**
- API Gateway 패턴
- 인증/인가 중앙화
- 서비스 디스커버리

#### 4.3 gRPC 서비스 간 통신

**왜 필요한가?**
- REST API는 텍스트 기반 (느림)
- gRPC는 바이너리 프로토콜 (빠름)
- 타입 안정성 보장

**기능 설명:**
```
Payment Service가 User Service에 사용자 정보 요청
→ gRPC로 통신 (빠르고 타입 안전)
→ Protocol Buffers로 데이터 직렬화
```

**구현 방법:**
1. Protocol Buffers 정의
2. gRPC 서버/클라이언트 구현
3. 서비스 간 통신

**학습 포인트:**
- gRPC vs REST
- Protocol Buffers
- 서비스 간 통신 패턴

#### 4.4 이벤트 기반 아키텍처 (Event Bus)

**왜 필요한가?**
- 서비스 간 느슨한 결합
- 비동기 처리
- 확장성 향상

**기능 설명:**
```
사용자가 제품 구매
→ Payment Service가 "결제 완료" 이벤트 발행
→ Notification Service가 이벤트 구독 → 이메일 발송
→ Inventory Service가 이벤트 구독 → 재고 차감
(서로 직접 통신하지 않음)
```

**구현 방법:**
1. RabbitMQ 또는 Kafka 설정
2. 이벤트 발행자/구독자 구현
3. 이벤트 스키마 정의

**학습 포인트:**
- 이벤트 기반 아키텍처
- 메시지 큐의 역할
- 이벤트 소싱 (선택)

#### 4.5 분산 추적 (Distributed Tracing)

**왜 필요한가?**
- 여러 서비스를 거치는 요청 추적 어려움
- 성능 병목 지점 파악
- 디버깅 용이

**기능 설명:**
```
사용자 요청 → API Gateway → User Service → DB
              → Content Service → Elasticsearch
각 단계마다 추적 ID 추가
→ 전체 흐름을 하나의 트레이스로 볼 수 있음
```

**구현 방법:**
1. OpenTelemetry 설정
2. Jaeger 또는 Zipkin 연동
3. 각 서비스에 추적 코드 추가

**학습 포인트:**
- 분산 추적의 필요성
- Trace vs Span
- 성능 분석

### 🔧 기술 스택 추가

- `@grpc/grpc-js`: gRPC 구현
- `amqplib`: RabbitMQ 클라이언트
- `@opentelemetry/api`: 분산 추적
- `jaeger-client`: Jaeger 클라이언트

### 📝 체크리스트

- [ ] 서비스 분리 설계
- [ ] API Gateway 구현
- [ ] 각 서비스를 독립적으로 배포
- [ ] gRPC 서비스 간 통신
- [ ] 이벤트 버스 구현
- [ ] 분산 추적 설정
- [ ] 서비스 디스커버리 구현

---

## 5단계: 쿠버네티스 & 고급 DevOps (4-6개월)

### 🎯 목표
- 컨테이너 오케스트레이션
- 자동 스케일링
- 고가용성 시스템 구축

### 📦 구현할 기능들

#### 5.1 쿠버네티스 기본 개념

**왜 필요한가?**
- Docker Compose는 단일 서버용
- 여러 서버에서 컨테이너 관리 필요
- 자동 복구, 스케일링, 로드 밸런싱

**기능 설명:**
```
쿠버네티스 클러스터:
[Master Node] - 관리
  └── [Worker Node 1] - 컨테이너 실행
  └── [Worker Node 2] - 컨테이너 실행
  └── [Worker Node 3] - 컨테이너 실행

컨테이너가 죽으면 → 자동으로 재시작
트래픽 증가 시 → 자동으로 컨테이너 추가
```

**구현 방법:**
1. 로컬에서 Minikube 또는 Kind로 학습
2. GKE(Google Kubernetes Engine) 설정
3. Pod, Service, Deployment 이해

**학습 포인트:**
- Pod, Service, Deployment 개념
- 레플리카셋과 스케일링
- 서비스 디스커버리

#### 5.2 Helm 차트로 배포 자동화

**왜 필요한가?**
- 쿠버네티스 YAML 파일이 많고 복잡
- Helm은 패키지 매니저처럼 관리
- 재사용 가능한 템플릿

**기능 설명:**
```
Helm 차트 = 애플리케이션 패키지
→ 한 번 정의하면 여러 환경에 배포 가능
→ 값(Values)만 변경하면 dev/staging/prod 배포
```

**구현 방법:**
1. Helm 차트 생성
2. 템플릿 작성
3. values.yaml로 환경별 설정

**학습 포인트:**
- Helm의 역할
- 템플릿 엔진
- 차트 버전 관리

#### 5.3 HPA (Horizontal Pod Autoscaler)

**왜 필요한가?**
- 트래픽에 따라 자동으로 컨테이너 수 조정
- 수동 스케일링 불필요
- 비용 최적화

**기능 설명:**
```
CPU 사용률이 70% 초과
→ HPA가 자동으로 Pod 수 증가 (2개 → 4개)
CPU 사용률이 30% 미만
→ HPA가 자동으로 Pod 수 감소 (4개 → 2개)
```

**구현 방법:**
1. HPA 리소스 정의
2. 메트릭 수집 설정
3. 스케일링 정책 설정

**학습 포인트:**
- 자동 스케일링 전략
- 메트릭 기반 스케일링
- 스케일링 지연 시간

#### 5.4 서비스 메시 (Service Mesh) - Istio

**왜 필요한가?**
- 서비스 간 통신 관리
- 트래픽 제어, 보안, 관찰성
- 코드 변경 없이 기능 추가

**기능 설명:**
```
서비스 메시 = 서비스 간 통신을 관리하는 레이어
→ A/B 테스트 (트래픽 분할)
→ 회로 차단기 (장애 서비스 차단)
→ 자동 재시도
```

**구현 방법:**
1. Istio 설치
2. VirtualService 정의
3. 트래픽 라우팅 규칙 설정

**학습 포인트:**
- 서비스 메시의 역할
- 사이드카 패턴
- 트래픽 관리

#### 5.5 모니터링 & 알림 (Prometheus + Grafana)

**왜 필요한가?**
- 시스템 상태 실시간 모니터링
- 문제 발생 시 즉시 알림
- 성능 메트릭 시각화

**기능 설명:**
```
Prometheus: 메트릭 수집
→ CPU, 메모리, 요청 수, 에러율 등

Grafana: 대시보드 시각화
→ 그래프로 메트릭 표시

Alertmanager: 알림 발송
→ 에러율이 5% 초과 시 슬랙 알림
```

**구현 방법:**
1. Prometheus 설정
2. Grafana 대시보드 생성
3. Alertmanager 규칙 정의

**학습 포인트:**
- 메트릭 수집
- 대시보드 설계
- 알림 규칙 설정

### 🔧 기술 스택 추가

- Kubernetes (GKE)
- Helm
- Istio (선택)
- Prometheus
- Grafana

### 📝 체크리스트

- [ ] 쿠버네티스 클러스터 설정
- [ ] Helm 차트 작성
- [ ] HPA 설정
- [ ] 모니터링 시스템 구축
- [ ] 알림 시스템 설정
- [ ] 블루-그린 배포 구현
- [ ] 서비스 메시 연동 (선택)

---

## 6단계: 고급 운영 & 최적화 (지속적)

### 🎯 목표
- 시스템 안정성 향상
- 비용 최적화
- 지속적 개선

### 📦 구현할 기능들

#### 6.1 인프라 코드화 (Terraform)

**왜 필요한가?**
- 수동으로 인프라 생성 → 실수 가능
- 코드로 관리 → 버전 관리, 재현 가능
- 여러 환경에 동일하게 배포

**기능 설명:**
```
Terraform 코드 작성
→ terraform apply 실행
→ GCP 리소스 자동 생성 (VM, DB, 네트워크 등)
→ 코드 변경 시 인프라 자동 업데이트
```

**구현 방법:**
1. Terraform 설치
2. GCP 프로바이더 설정
3. 리소스 정의

**학습 포인트:**
- IaC (Infrastructure as Code)
- Terraform 상태 관리
- 모듈화

#### 6.2 블루-그린 배포

**왜 필요한가?**
- 무중단 배포
- 빠른 롤백
- 프로덕션 안정성

**기능 설명:**
```
Blue 환경: 현재 운영 중인 버전
Green 환경: 새 버전 배포
→ 트래픽을 Blue에서 Green으로 전환
→ 문제 발생 시 즉시 Blue로 롤백
```

**구현 방법:**
1. 두 개의 환경 준비
2. 로드 밸런서로 트래픽 전환
3. 자동화 스크립트 작성

**학습 포인트:**
- 배포 전략 비교
- 롤백 전략
- 트래픽 전환

#### 6.3 성능 테스트 자동화

**왜 필요한가?**
- 배포 전 성능 검증
- 병목 지점 사전 발견
- 사용자 경험 보장

**기능 설명:**
```
CI/CD 파이프라인에 성능 테스트 추가
→ 배포 전 자동으로 부하 테스트 실행
→ 성능 기준 미달 시 배포 중단
```

**구현 방법:**
1. k6 또는 Artillery 설정
2. 성능 테스트 시나리오 작성
3. CI/CD 파이프라인에 통합

**학습 포인트:**
- 부하 테스트 도구
- 성능 메트릭
- 병목 분석

#### 6.4 보안 스캔 자동화

**왜 필요한가?**
- 보안 취약점 사전 발견
- 의존성 취약점 검사
- 컴플라이언스 준수

**기능 설명:**
```
CI/CD 파이프라인에 보안 스캔 추가
→ 코드 스캔 (정적 분석)
→ 의존성 스캔 (npm audit)
→ 컨테이너 스캔
→ 취약점 발견 시 알림
```

**구현 방법:**
1. Snyk 또는 Dependabot 설정
2. Trivy로 컨테이너 스캔
3. CI/CD 파이프라인에 통합

**학습 포인트:**
- 보안 스캔 도구
- 취약점 관리
- 보안 모범 사례

### 🔧 기술 스택 추가

- Terraform
- k6 / Artillery
- Snyk / Dependabot
- Trivy

### 📝 체크리스트

- [ ] Terraform으로 인프라 코드화
- [ ] 블루-그린 배포 구현
- [ ] 성능 테스트 자동화
- [ ] 보안 스캔 자동화
- [ ] 비용 모니터링
- [ ] 문서화 자동화

---

## 🎓 학습 체크리스트

### 전체 진행 상황

#### 1단계: 실시간 기능 & 고급 인증
- [ ] WebSocket 실시간 채팅/알림
- [ ] Redis 세션 관리
- [ ] 파일 업로드 개선
- [ ] Cloud Storage 연동

#### 2단계: 성능 최적화 & 캐싱
- [ ] Redis 캐싱 레이어
- [ ] 데이터베이스 쿼리 최적화
- [ ] CDN 연동
- [ ] GraphQL API (선택)

#### 3단계: 검색 엔진 & 고급 기능
- [ ] Elasticsearch 검색 엔진
- [ ] 결제 시스템 연동
- [ ] Rate Limiting & 보안 강화
- [ ] 이메일 발송 시스템

#### 4단계: 마이크로서비스 아키텍처
- [ ] 서비스 분리 전략
- [ ] API Gateway 구현
- [ ] gRPC 서비스 간 통신
- [ ] 이벤트 기반 아키텍처
- [ ] 분산 추적

#### 5단계: 쿠버네티스 & 고급 DevOps
- [ ] 쿠버네티스 클러스터 설정
- [ ] Helm 차트 작성
- [ ] HPA 설정
- [ ] 모니터링 시스템 구축
- [ ] 서비스 메시 연동 (선택)

#### 6단계: 고급 운영 & 최적화
- [ ] 인프라 코드화 (Terraform)
- [ ] 블루-그린 배포
- [ ] 성능 테스트 자동화
- [ ] 보안 스캔 자동화

---

## 📖 학습 방법론

### 1. AI 활용 (Cursor)

**언제 사용하나?**
- 기능 구현 시 초기 코드 생성
- 에러 해결
- 코드 리팩토링 제안

**예시:**
```
"Redis를 사용해서 블로그 목록을 캐싱하는 미들웨어를 만들어줘"
→ AI가 코드 생성
→ 작동 확인
→ 역공학으로 이해
```

### 2. 역공학 (Reverse Engineering)

**어떻게 하나?**
1. 작동하는 코드를 먼저 만들기
2. 코드를 한 줄씩 분석
3. "왜 이렇게 작동하는가?" 질문
4. 공식 문서와 비교

**예시:**
```typescript
// AI가 생성한 코드
const cacheKey = `blog:list:${page}`;
const cached = await redis.get(cacheKey);
if (cached) return JSON.parse(cached);

// 역공학 질문들:
// - 왜 키를 이렇게 만들었을까?
// - JSON.parse가 왜 필요할까?
// - TTL은 어떻게 설정할까?
```

### 3. 실전 프로젝트 중심

**왜 중요한가?**
- 이론만으로는 부족
- 실제 문제 해결 경험
- 포트폴리오로 활용

**방법:**
- 각 단계마다 현재 프로젝트에 적용
- 작은 기능부터 시작
- 점진적으로 확장

### 4. 문서화 습관

**무엇을 문서화하나?**
- 구현한 기능 설명
- 문제 해결 과정
- 학습한 개념 정리

**형식:**
- Markdown 파일
- 코드 주석
- 다이어그램 (Mermaid)

---

## 🚀 시작하기

### 첫 번째 단계

1. **1단계부터 시작**
   - WebSocket 실시간 알림 기능 구현
   - Cursor AI 도움 받기
   - 작동 확인 후 역공학

2. **문서화**
   - 구현한 내용을 `LEARNING.md`에 기록
   - 다이어그램으로 구조 설명

3. **배포**
   - Docker Compose에 추가
   - GitHub Actions로 자동 배포
   - 실제 환경에서 테스트

### 진행 순서 권장사항

```
1단계 완료 → 2단계 시작
2단계 완료 → 3단계 시작
...
```

각 단계를 완전히 이해한 후 다음 단계로 진행하는 것을 권장합니다.

---

## 📚 추천 학습 자료

### 공식 문서
- [Docker 공식 문서](https://docs.docker.com/)
- [Kubernetes 공식 문서](https://kubernetes.io/docs/)
- [Redis 공식 문서](https://redis.io/docs/)
- [Elasticsearch 공식 문서](https://www.elastic.co/guide/)

### 온라인 강의
- Udemy DevOps 강의
- 인프런 DevOps 강의
- YouTube 튜토리얼

### 책
- "도커 & 쿠버네티스" (시리즈)
- "마이크로서비스 패턴"
- "클린 아키텍처"

---

## 💡 팁

1. **작은 것부터 시작**
   - 한 번에 모든 것을 구현하려 하지 말기
   - 작은 기능부터 완성

2. **에러는 학습 기회**
   - 에러 메시지를 자세히 읽기
   - 스택 오버플로우 검색
   - 공식 문서 확인

3. **커뮤니티 활용**
   - GitHub Issues
   - Stack Overflow
   - Discord/Slack 커뮤니티

4. **정기적인 리뷰**
   - 주간 학습 내용 정리
   - 다음 주 목표 설정
   - 진행 상황 체크

---

## 🎯 최종 목표

이 로드맵을 완료하면:

✅ **기술적 역량**
- 마이크로서비스 아키텍처 설계 및 구현
- 쿠버네티스 클러스터 운영
- 분산 시스템 디버깅
- 고가용성 시스템 구축

✅ **DevOps 역량**
- CI/CD 파이프라인 구축
- 인프라 코드화
- 모니터링 및 알림 시스템
- 자동화된 배포 전략

✅ **문제 해결 능력**
- 복잡한 시스템 문제 분석
- 성능 최적화
- 보안 강화
- 확장성 설계

---

## 📝 마무리

이 로드맵은 **가이드라인**입니다. 자신의 속도에 맞춰 학습하고, 필요하면 순서를 바꿔도 됩니다.

**가장 중요한 것**: 꾸준함과 실전 경험입니다.

화이팅! 🚀

